# **1. The Problem of Knowing What Works**

### 1.1 The Uncertainty of Healing
Human healing is noisy—symptoms fluctuate, diseases wax and wane, and people naturally improve even without treatment.

### 1.2 Oral Tradition and Story-Based Medicine
Before writing or measurement, knowledge was transmitted as stories. These narratives built medical authority but also magnified misinterpretations.

### 1.3 Early Moves Toward Systematic Reasoning
Thinkers in antiquity (e.g., Hippocrates) began advocating method and documentation over inherited dogma.

### 1.4 Why Humans Misinterpret Patterns
Our cognition is built to find structure—even when none exists—making medicine particularly vulnerable to error.

### 1.5 Key Vocabulary
- Anecdotal Evidence  
- Availability Heuristic  
- Confirmation Bias  
- Recall Bias  
- Regression to the Mean  
- Natural History of Disease  

### Historical Anchor (JLL)
- Hippocrates stressed the need to start inquiry from known discoveries, reinforcing early attempts to ground medicine beyond anecdote.  
  **Citation:** 

### End-of-Chapter Section
**Question Stems for Application (placeholder)**

---

# **2. When Authority Fails: The Rise of Empirical Thinking**

### 2.1 Why Authority Dominated Early Medicine
For centuries, knowledge rested on reputation, lineage, and textual inheritance.

### 2.2 From Storytellers to Sages
Medical doctrines became ossified under prestigious figures, slowing innovation.

### 2.3 Cracks in Traditional Doctrine
Clinicians increasingly noticed inconsistencies between theory and experience.

### 2.4 Turning Toward Empirical Methods
Figures like al-Razi explicitly *tested* recommendations, contrasting treated and untreated groups.

### 2.5 The Enduring Power of Anecdote
Humans still privilege compelling stories—today echoed by social media influencers and modern misinformation dynamics.

### 2.6 Key Vocabulary
- Hierarchy of Evidence  
- Biological Plausibility  

### Historical Anchor (JLL)
- Al-Razi recognized the importance of untreated comparison groups, representing a major break from authority-based medicine.  
  **Citation:** 

### End-of-Chapter Section
**Question Stems for Application (placeholder)**

---

# **3. The Limits of Observation: Why Measurement Matters**

### 3.1 Problems With Casual Observation
Observers tend to see what they expect to see, and early records lacked consistency.

### 3.2 Structured Clinical Recording
Systematic observation—timelines, symptoms, numeration—created reproducible data.

### 3.3 The Need for Reliable Measurement
Measurement allowed detection of patterns that were invisible to intuition.

### 3.4 How Measurement Enabled Comparison
Once data were structured, different treatments could be compared meaningfully.

### 3.5 Key Vocabulary
- Surrogate Outcomes  
- Internal Validity  
- Bias (Systematic Error)  
- Chance (Random Error)

### Historical Anchor (JLL)
- The shift toward numerical methods and systematic clinical instruction marks early recognition of the limitations of casual observation (Louis, 1834).  
  **Citation:** 

### End-of-Chapter Section
**Question Stems for Application (placeholder)**

---

# **4. From Observation to Testing: Why We Intervene**

### 4.1 Why Observation Cannot Establish Causation
Correlation and temporal association are not sufficient to infer cause.

### 4.2 Hume and the Problem of Causation
Hume’s critique underscored that repeated observation alone does not reveal the counterfactual.

### 4.3 The Logic of Intervention
To test causality, medicine had to move from observing disease to *manipulating* treatments.

### 4.4 Early Attempts at Deliberate Testing
Experimental reasoning slowly entered medicine through intentional contrasts and trials.

### 4.5 Key Vocabulary
- The Counterfactual  
- Confounding Variables  
- Control Group  

### Historical Anchor (JLL)
- Roger Bacon's assertion—“without experiment nothing can be sufficiently known”—captures early methodological thinking that moved beyond passive observation.  
  **Citation:** 

### End-of-Chapter Section
**Question Stems for Application (placeholder)**

---

# **5. The Logic of Comparison: Isolating Treatment Effects**

### 5.1 The Problem of Natural History
Without understanding baseline course, apparent improvement can mislead.

### 5.2 Types of Comparisons
Concurrent, historical, within-person, and between-person designs.

### 5.3 Early Comparative Trials
James Lind’s scurvy comparison is a canonical example of structured comparison.

### 5.4 Expectation, Placebo, and Context
Early recognition that belief and ritual themselves affect healing.

### 5.5 Key Vocabulary
- Placebo Effect  
- Selection Bias  
- Control Group  
- Natural History of Disease (revisited)

### Historical Anchor (JLL)
- James Lind’s famous comparison of citrus vs. alternatives demonstrates early systematic concurrent allocation.  
  **Citation:** 

### End-of-Chapter Section
**Question Stems for Application (placeholder)**

---

# **6. The Architecture of Fair Tests: Avoiding Bias and Chance**

### 6.1 Why Comparisons Still Mislead
Unequal groups, expectation, co-interventions, or selective reporting can distort results.

### 6.2 Historical Lessons on Unfair Testing
Medical history is full of persuasive but misleading tests due to uncontrolled factors.

### 6.3 Principles of Fair Testing
Randomization, allocation concealment, blinding, attrition control.

### 6.4 Managing Chance and Variability
Larger samples reduce random error, but not systematic bias.

### 6.5 Key Vocabulary
- Randomization  
- Allocation Concealment  
- Blinding  
- Attrition Bias  
- Internal Validity  

### Historical Anchor (JLL)
- The 1948 MRC streptomycin trial introduced explicit methods to prevent foreknowledge of assignment.  
  **Citation:** 

### End-of-Chapter Section
**Question Stems for Application (placeholder)**

---

# **7. Synthesizing Evidence: Making Sense Across Studies**

### 7.1 Why One Study Is Never Enough
Single studies are limited in precision and scope.

### 7.2 Early Evidence Summaries
Physicians historically aggregated multiple cases, though informally.

### 7.3 How Synthesis Changes Understanding
Systematic reviews and meta-analysis allow more stable, comprehensive estimates.

### 7.4 Key Vocabulary
- Systematic Review  
- Meta-Analysis  
- Heterogeneity  
- Grey Literature  
- Publication Bias  
- Precision  

### Historical Anchor (JLL)
- Early numerical methods and modern systematic review commentary reflect the need to aggregate evidence.  
  **Citation:** 

### End-of-Chapter Section
**Question Stems for Application (placeholder)**

---

# **8. The Challenge of Generalizing Evidence: What Works Here May Not Work There**

### 8.1 Why External Validity Matters
Populations, settings, and disease spectra differ; treatment effects often vary.

### 8.2 When Evidence Fails to Travel
Historical examples show treatments that succeeded in one context failed in another.

### 8.3 Internal vs. External Validity
Strong causal identification *within* a study does not guarantee broad applicability.

### 8.4 Early Recognitions of Non-Generalisability
Scadding and others emphasized clinical scepticism and context awareness.

### 8.5 Key Vocabulary
- External Validity  
- Generalizability  
- Effect Modification  
- Spectrum Bias  

### Historical Anchor (JLL)
- Scadding’s pragmatism highlights the challenge of applying evidence across populations.  
  **Citation:** 

### End-of-Chapter Section
**Question Stems for Application (placeholder)**

---

# **9. The Rise of Modern Standards and Evidence Infrastructure**

### 9.1 Industrialization of Scientific Knowledge
Printing, professional societies, registries, and reporting standards.

### 9.2 Emergence of Modern RCTs
From structured comparison to allocation schedules and formalized protocols.

### 9.3 Regulation as Institutionalized Evidence
Recognition that approval and safety systems must rely on rigorous trial thresholds.

### 9.4 Cultural Shifts Toward Accountability
Scientific norms around transparency and replication respond to past failures.

### 9.5 Key Vocabulary
- Pre-appraised Evidence  
- Reporting Bias  
- Researcher/Sponsor Bias  

### Historical Anchor (JLL)
- The development of fair allocation schedules and subsequent regulatory processes increased trial rigor.  
  **Citation:** 

### End-of-Chapter Section
**Question Stems for Application (placeholder)**

---

# **10. The Digital Transformation of Evidence**

### 10.1 When Knowledge Became Searchable
Digital indexing replaced manual library-based searching.

### 10.2 How Digital Search Changed Clinical Reasoning
Speed increased, but selectivity and bias in search algorithms introduced new vulnerabilities.

### 10.3 New Digital Vulnerabilities
Information overload and misinformation accelerated.

### 10.4 Social Media as Modern Oral Tradition
Influencer narratives recapitulate ancient anecdote transmission at unprecedented scale.

### 10.5 Key Vocabulary
- Pre-appraised Evidence (digital form)  
- Cognitive Load  
- Information Bias  

### Historical Anchor (JLL)
- The JLL timeline’s digital transformation illustrates the shift to accessible, curated historical evidence.  
  **Citation:** 

### End-of-Chapter Section
**Question Stems for Application (placeholder)**

---

# **11. AI as a New Evidence Infrastructure: From Searching to Supervising**

### 11.1 What AI Changes in Evidence Use
AI automates retrieval, synthesis, and summarization—shifting clinicians from searchers to supervisors.

### 11.2 New Failure Modes Introduced by AI
Hallucination, overgeneralization, automation bias, lack of explainability.

### 11.3 Why Clinicians Must Supervise AI
Understanding study design and reasoning remains essential to detect invalid claims.

### 11.4 Historical Echoes of New Authority
AI functions as a new “expert,” echoing past eras when deference to authority impeded critical appraisal.

### 11.5 Key Vocabulary
- Automation Bias  
- Hallucination  
- Verification  
- Traceability  

### Historical Anchor (JLL)
- Placebo trick-trials and the debunking of mesmerism illustrate the dangers of trusting persuasive systems without verification—a lesson now resurfacing with AI.  
  **Citation:** 

### End-of-Chapter Section
**Question Stems for Application (placeholder)**
